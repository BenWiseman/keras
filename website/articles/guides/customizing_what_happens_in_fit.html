<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Customizing what happens in `fit()` • keras</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../../bootstrap-toc.css">
<script src="../../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../pkgdown.js"></script><link href="../../extra.css" rel="stylesheet">
<script src="../../extra.js"></script><meta property="og:title" content="Customizing what happens in `fit()`">
<meta property="og:description" content="keras">
<meta property="og:image" content="/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../../index.html">keras</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">2.4.0.9002</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Tutorials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/getting_started.html">Getting Started</a>
    </li>
    <li>
      <a href="../../articles/tutorial_basic_classification.html">Basic Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial_basic_text_classification.html">Text Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial_basic_regression.html">Basic Regression</a>
    </li>
    <li>
      <a href="../../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    </li>
    <li>
      <a href="../../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">Using Keras</li>
    <li>
      <a href="../../articles/guide_keras.html">Guide to Keras Basics</a>
    </li>
    <li>
      <a href="../../articles/sequential_model.html">Sequential Model in Depth</a>
    </li>
    <li>
      <a href="../../articles/functional_api.html">Functional API in Depth</a>
    </li>
    <li>
      <a href="../../articles/about_keras_models.html">About Keras Models</a>
    </li>
    <li>
      <a href="../../articles/about_keras_layers.html">About Keras Layers</a>
    </li>
    <li>
      <a href="../../articles/training_visualization.html">Training Visualization</a>
    </li>
    <li>
      <a href="../../articles/applications.html">Pre-Trained Models</a>
    </li>
    <li>
      <a href="../../articles/faq.html">Frequently Asked Questions</a>
    </li>
    <li>
      <a href="../../articles/why_use_keras.html">Why Use Keras?</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Advanced</li>
    <li>
      <a href="../../articles/eager_guide.html">Eager Execution</a>
    </li>
    <li>
      <a href="../../articles/training_callbacks.html">Training Callbacks</a>
    </li>
    <li>
      <a href="../../articles/backend.html">Keras Backend</a>
    </li>
    <li>
      <a href="../../articles/custom_layers.html">Custom Layers</a>
    </li>
    <li>
      <a href="../../articles/custom_models.html">Custom Models</a>
    </li>
    <li>
      <a href="../../articles/saving_serializing.html">Saving and serializing</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Guides (New for TF 2)
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/python_subclasses.html">Python Subclasses</a>
    </li>
    <li>
      <a href="../../articles/guides/customizing_what_happens_in_fit.html">Customizing what happens in fit</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../articles/learn.html">Learn</a>
</li>
<li>
  <a href="../../articles/tools.html">Tools</a>
</li>
<li>
  <a href="../../articles/examples/index.html">Examples</a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
<li>
  <a href="../../news/index.html">News</a>
</li>
<li>
  <a href="https://github.com/rstudio/keras">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/rstudio/keras/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="customizing_what_happens_in_fit_files/header-attrs-2.9.7/header-attrs.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Customizing what happens in <code>fit()</code>
</h1>
                        <h4 class="author">
<a href="https://twitter.com/fchollet">fchollet</a>, <a href="https://github.com/t-kalinowski">t-kalinowski</a>
</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/master/vignettes/guides/customizing_what_happens_in_fit.Rmd"><code>vignettes/guides/customizing_what_happens_in_fit.Rmd</code></a></small>
      <div class="hidden name"><code>customizing_what_happens_in_fit.Rmd</code></div>

    </div>

    
    
<hr>
<div id="introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h2>
<p>When you’re doing supervised learning, you can use <code><a href="https://generics.r-lib.org/reference/fit.html">fit()</a></code> and everything works smoothly.</p>
<p>When you need to write your own training loop from scratch, you can use the <code>tf$GradientTape</code> and take control of every little detail.</p>
<p>But what if you need a custom training algorithm, but you still want to benefit from the convenient features of <code><a href="https://generics.r-lib.org/reference/fit.html">fit()</a></code>, such as callbacks, built-in distribution support, or step fusing?</p>
<p>A core principle of Keras is <strong>progressive disclosure of complexity</strong>. You should always be able to get into lower-level workflows in a gradual way. You shouldn’t fall off a cliff if the high-level functionality doesn’t exactly match your use case. You should be able to gain more control over the small details while retaining a commensurate amount of high-level convenience.</p>
<p>When you need to customize what <code><a href="https://generics.r-lib.org/reference/fit.html">fit()</a></code> does, you should <strong>override the training step function of the <code>Model</code> class</strong>. This is the function that is called by <code><a href="https://generics.r-lib.org/reference/fit.html">fit()</a></code> for every batch of data. You will then be able to call <code><a href="https://generics.r-lib.org/reference/fit.html">fit()</a></code> as usual – and it will be running your own learning algorithm.</p>
<p>Note that this pattern does not prevent you from building models with the Functional API. You can do this whether you’re building <code>Sequential</code> models, Functional API models, or subclassed models.</p>
<p>Let’s see how that works.</p>
</div>
<div id="setup" class="section level2">
<h2 class="hasAnchor">
<a href="#setup" class="anchor"></a>Setup</h2>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tensorflow">tensorflow</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tfdatasets">tfdatasets</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://keras.rstudio.com">keras</a></span><span class="op">)</span>

<span class="co">## to run this locally you'll need the development version of keras:</span>
<span class="co"># remotes::install_cran(c("purrr", "tfdatasets", "envir"))</span>
<span class="co"># remotes::install_github("rstudio/keras")</span>

<span class="co"># -- we start by defining some helpers we'll use later --</span>
<span class="va">zip</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">...</span><span class="op">)</span> <span class="fu">purrr</span><span class="fu">::</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/transpose.html">transpose</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">...</span><span class="op">)</span><span class="op">)</span>

<span class="va">map_and_name</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">.x</span>, <span class="va">.f</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">out</span> <span class="op">&lt;-</span> <span class="fu">purrr</span><span class="fu">::</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map</a></span><span class="op">(</span><span class="va">.x</span>, <span class="va">.f</span><span class="op">[</span><span class="op">-</span><span class="fl">2L</span><span class="op">]</span>, <span class="va">...</span><span class="op">)</span>
  <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">out</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu">purrr</span><span class="fu">::</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_chr</a></span><span class="op">(</span><span class="va">.x</span>, <span class="va">.f</span><span class="op">[</span><span class="op">-</span><span class="fl">3L</span><span class="op">]</span>, <span class="va">...</span><span class="op">)</span>
  <span class="va">out</span>
<span class="op">}</span>
  
<span class="va">`%&lt;-active%`</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">sym</span>, <span class="va">fun</span><span class="op">)</span>
  <span class="fu"><a href="https://rdrr.io/r/base/bindenv.html">makeActiveBinding</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/substitute.html">substitute</a></span><span class="op">(</span><span class="va">sym</span><span class="op">)</span>, <span class="va">fun</span>, <span class="fu"><a href="https://rdrr.io/r/base/sys.parent.html">parent.frame</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span>

<span class="fu">envir</span><span class="fu">::</span><span class="fu"><a href="https://t-kalinowski.github.io/envir/reference/import_from.html">import_from</a></span><span class="op">(</span><span class="va">magrittr</span>, <span class="va">`%&lt;&gt;%`</span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/stopifnot.html">stopifnot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/tf_config.html">tf_version</a></span><span class="op">(</span><span class="op">)</span> <span class="op">&gt;=</span> <span class="st">"2.2"</span><span class="op">)</span> <span class="co"># Requires TensorFlow 2.2 or later.</span></code></pre></div>
</div>
<div id="a-first-simple-example" class="section level2">
<h2 class="hasAnchor">
<a href="#a-first-simple-example" class="anchor"></a>A first simple example</h2>
<p>Let’s start from a simple example:</p>
<ul>
<li>We create a new class that subclasses <code>keras$Model</code>.</li>
<li>We just override the method <code>train_step(self, data)</code>.</li>
<li>We return a named list mapping metric names (including the loss) to their current value.</li>
</ul>
<p>The input argument <code>data</code> is what gets passed to fit as training data:</p>
<ul>
<li>If you pass arrays, by calling <code>fit(x, y, ...)</code>, then <code>data</code> will be the tuple <code>(x, y)</code>
</li>
<li>If you pass a <code>tf.data.Dataset</code>, by calling <code>fit(dataset, ...)</code>, then <code>data</code> will be what gets yielded by <code>dataset</code> at each batch.</li>
</ul>
<p>In the body of the <code>train_step</code> method, we implement a regular training update, similar to what you are already familiar with. Importantly, <strong>we compute the loss via <code>self$compiled_loss</code></strong>, which wraps the loss(es) function(s) that were passed to <code><a href="https://generics.r-lib.org/reference/compile.html">compile()</a></code>.</p>
<p>Similarly, we call <code>self$compiled_metrics$update_state(y, y_pred)</code> to update the state of the metrics that were passed in <code><a href="https://generics.r-lib.org/reference/compile.html">compile()</a></code>, and we query results from <code>self$metrics</code> at the end to retrieve their current value.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">CustomModel</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">Model</span><span class="op">)</span> <span class="op"><a href="../../reference/%py_class%.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">train_step</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">self</span>, <span class="va">data</span><span class="op">)</span> <span class="op">{</span>
    <span class="co"># Unpack the data. Its structure depends on your model and</span>
    <span class="co"># on what you pass to `fit()`.</span>
    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span> <span class="op"><a href="../../reference/%&lt;-%.html">%&lt;-%</a></span> <span class="va">data</span>
    
    <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">GradientTape</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/reticulate/man/with-as-operator.html">%as%</a></span> <span class="va">tape</span>, <span class="op">{</span>
      <span class="va">y_pred</span> <span class="op">=</span> <span class="fu">self</span><span class="op">(</span><span class="va">x</span>, training <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>  <span class="co"># Forward pass</span>
      <span class="co"># Compute the loss value</span>
      <span class="co"># (the loss function is configured in `compile()`)</span>
      <span class="va">loss</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">compiled_loss</span><span class="op">(</span><span class="va">y</span>, <span class="va">y_pred</span>, regularization_losses <span class="op">=</span> <span class="va">self</span><span class="op">$</span><span class="va">losses</span><span class="op">)</span>
    <span class="op">}</span><span class="op">)</span>
    
    <span class="co"># Compute gradients</span>
    <span class="va">trainable_vars</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="va">trainable_variables</span>
    <span class="va">gradients</span> <span class="op">&lt;-</span> <span class="va">tape</span><span class="op">$</span><span class="fu">gradient</span><span class="op">(</span><span class="va">loss</span>, <span class="va">trainable_vars</span><span class="op">)</span>
    <span class="co"># Update weights</span>
    <span class="va">self</span><span class="op">$</span><span class="va">optimizer</span><span class="op">$</span><span class="fu">apply_gradients</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/zip.html">zip</a></span><span class="op">(</span><span class="va">gradients</span>, <span class="va">trainable_vars</span><span class="op">)</span><span class="op">)</span>
    <span class="co"># Update metrics (includes the metric that tracks the loss)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">compiled_metrics</span><span class="op">$</span><span class="fu">update_state</span><span class="op">(</span><span class="va">y</span>, <span class="va">y_pred</span><span class="op">)</span>
    
    <span class="co"># Return a named list mapping metric names to current value</span>
    <span class="fu">map_and_name</span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">metrics</span>, <span class="va">.x</span><span class="op">$</span><span class="va">name</span> <span class="op">~</span> <span class="va">.x</span><span class="op">$</span><span class="fu">result</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>
  <span class="op">}</span>
<span class="op">}</span></code></pre></div>
<p>Let’s try this out:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Construct and compile an instance of CustomModel</span>
<span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_input.html">layer_input</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html">shape</a></span><span class="op">(</span><span class="fl">32</span><span class="op">)</span><span class="op">)</span>
<span class="va">outputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="va">inputs</span>, units <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">CustomModel</span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span>
<span class="va">model</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span>optimizer <span class="op">=</span> <span class="st">"adam"</span>,
                  loss <span class="op">=</span> <span class="st">"mse"</span>,
                  metrics <span class="op">=</span> <span class="st">"mae"</span><span class="op">)</span>

<span class="co"># Just use `fit` as usual</span>
<span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/k_random_uniform.html">k_random_uniform</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1000</span>, <span class="fl">32</span><span class="op">)</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/k_random_uniform.html">k_random_uniform</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1000</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="va">model</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, epochs <span class="op">=</span> <span class="fl">3</span>, verbose <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></code></pre></div>
</div>
<div id="going-lower-level" class="section level2">
<h2 class="hasAnchor">
<a href="#going-lower-level" class="anchor"></a>Going lower-level</h2>
<p>Naturally, you could just skip passing a loss function in <code><a href="https://generics.r-lib.org/reference/compile.html">compile()</a></code>, and instead do everything <em>manually</em> in <code>train_step</code>. Likewise for metrics.</p>
<p>Here’s a lower-level example, that only uses <code><a href="https://generics.r-lib.org/reference/compile.html">compile()</a></code> to configure the optimizer:</p>
<ul>
<li>We start by creating <code>Metric</code> instances to track our loss and a MAE score.</li>
<li>We implement a custom <code>train_step()</code> that updates the state of these metrics (by calling <code>update_state()</code> on them), then query them (via <code>result()</code>) to return their current average value, to be displayed by the progress bar and to be pass to any callback.</li>
<li>Note that we would need to call <code><a href="../../reference/reset_states.html">reset_states()</a></code> on our metrics between each epoch! Otherwise calling <code>result()</code> would return an average since the start of training, whereas we usually work with per-epoch averages. Thankfully, the framework can do that for us: just list any metric you want to reset in the <code>metrics</code> property of the model. The model will call <code><a href="../../reference/reset_states.html">reset_states()</a></code> on any object listed here at the beginning of each <code><a href="https://generics.r-lib.org/reference/fit.html">fit()</a></code> epoch or at the beginning of a call to <code><a href="https://rdrr.io/pkg/tensorflow/man/evaluate.html">evaluate()</a></code>.</li>
</ul>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">loss_tracker</span> <span class="op">&lt;-</span> <span class="va">keras</span><span class="op">$</span><span class="va">metrics</span><span class="op">$</span><span class="fu">Mean</span><span class="op">(</span>name<span class="op">=</span><span class="st">"loss"</span><span class="op">)</span>
<span class="va">mae_metric</span> <span class="op">&lt;-</span> <span class="va">keras</span><span class="op">$</span><span class="va">metrics</span><span class="op">$</span><span class="fu">MeanAbsoluteError</span><span class="op">(</span>name<span class="op">=</span><span class="st">"mae"</span><span class="op">)</span>

<span class="fu">CustomModel</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">Model</span><span class="op">)</span> <span class="op"><a href="../../reference/%py_class%.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">train_step</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">data</span><span class="op">)</span> <span class="op">{</span>
    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span> <span class="op"><a href="../../reference/%&lt;-%.html">%&lt;-%</a></span> <span class="va">data</span>
    
    <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">GradientTape</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/reticulate/man/with-as-operator.html">%as%</a></span> <span class="va">tape</span>, <span class="op">{</span>
      <span class="va">y_pred</span> <span class="op">=</span> <span class="fu">self</span><span class="op">(</span><span class="va">x</span>, training <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>  <span class="co"># Forward pass</span>
      <span class="co"># Compute our own loss</span>
      <span class="va">loss</span> <span class="op">=</span> <span class="va">keras</span><span class="op">$</span><span class="va">losses</span><span class="op">$</span><span class="fu">mean_squared_error</span><span class="op">(</span><span class="va">y</span>, <span class="va">y_pred</span><span class="op">)</span>
    <span class="op">}</span><span class="op">)</span>
    <span class="co"># Compute gradients</span>
    <span class="va">trainable_vars</span> <span class="op">=</span> <span class="va">self</span><span class="op">$</span><span class="va">trainable_variables</span>
    <span class="va">gradients</span> <span class="op">=</span> <span class="va">tape</span><span class="op">$</span><span class="fu">gradient</span><span class="op">(</span><span class="va">loss</span>, <span class="va">trainable_vars</span><span class="op">)</span>
    
    <span class="co"># Update weights</span>
    <span class="va">self</span><span class="op">$</span><span class="va">optimizer</span><span class="op">$</span><span class="fu">apply_gradients</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/zip.html">zip</a></span><span class="op">(</span><span class="va">gradients</span>, <span class="va">trainable_vars</span><span class="op">)</span><span class="op">)</span>
    
    <span class="co"># Compute our own metrics</span>
    <span class="va">loss_tracker</span><span class="op">$</span><span class="fu">update_state</span><span class="op">(</span><span class="va">loss</span><span class="op">)</span>
    <span class="va">mae_metric</span><span class="op">$</span><span class="fu">update_state</span><span class="op">(</span><span class="va">y</span>, <span class="va">y_pred</span><span class="op">)</span>
    <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>loss <span class="op">=</span> <span class="va">loss_tracker</span><span class="op">$</span><span class="fu">result</span><span class="op">(</span><span class="op">)</span>,
         mae <span class="op">=</span> <span class="va">mae_metric</span><span class="op">$</span><span class="fu">result</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>
  <span class="op">}</span>
  
  <span class="va">metrics</span> <span class="op">%&lt;-active%</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span>
    <span class="co"># We list our `Metric` objects here so that `reset_states()` can be</span>
    <span class="co"># called automatically at the start of each epoch</span>
    <span class="co"># or at the start of `evaluate()`.</span>
    <span class="co"># If you don't implement this property, you have to call</span>
    <span class="co"># `reset_states()` yourself at the time of your choosing.</span>
    <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">loss_tracker</span>, <span class="va">mae_metric</span><span class="op">)</span>
  <span class="op">}</span>
<span class="op">}</span>

<span class="co"># Construct an instance of CustomModel</span>
<span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_input.html">layer_input</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html">shape</a></span><span class="op">(</span><span class="fl">32</span><span class="op">)</span><span class="op">)</span>
<span class="va">outputs</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span> <span class="fu"><a href="../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">CustomModel</span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span>

<span class="co"># We don't pass a loss or metrics here</span>
<span class="va">model</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span>optimizer<span class="op">=</span><span class="st">"adam"</span><span class="op">)</span>

<span class="co"># Just use `fit` as usual -- you can use callbacks, etc.</span>
<span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/k_random_uniform.html">k_random_uniform</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1000</span>, <span class="fl">32</span><span class="op">)</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/k_random_uniform.html">k_random_uniform</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1000</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="va">model</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, epochs<span class="op">=</span><span class="fl">5</span><span class="op">)</span></code></pre></div>
</div>
<div id="supporting-sample_weight-class_weight" class="section level2">
<h2 class="hasAnchor">
<a href="#supporting-sample_weight-class_weight" class="anchor"></a>Supporting <code>sample_weight</code> &amp; <code>class_weight</code>
</h2>
<p>You may have noticed that our first basic example didn’t make any mention of sample weighting. If you want to support the <code><a href="https://generics.r-lib.org/reference/fit.html">fit()</a></code> arguments <code>sample_weight</code> and <code>class_weight</code>, you’d simply do the following:</p>
<ul>
<li>Unpack <code>sample_weight</code> from the <code>data</code> argument</li>
<li>Pass it to <code>compiled_loss</code> &amp; <code>compiled_metrics</code> (of course, you could also just apply it manually if you don’t rely on <code><a href="https://generics.r-lib.org/reference/compile.html">compile()</a></code> for losses &amp; metrics)</li>
<li>That’s it. That’s the list.</li>
</ul>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">CustomModel</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">Model</span><span class="op">)</span> <span class="op"><a href="../../reference/%py_class%.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">train_step</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">data</span><span class="op">)</span> <span class="op">{</span>
    <span class="co"># Unpack the data. A third element is `data` is optional, but if present</span>
    <span class="co"># it's assigned to sample_weight. Its structure depends on your model and on</span>
    <span class="co"># what you pass to `fit()`.</span>
    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, sample_weight <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op"><a href="../../reference/%&lt;-%.html">%&lt;-%</a></span> <span class="va">data</span>
    
    <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">GradientTape</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/reticulate/man/with-as-operator.html">%as%</a></span> <span class="va">tape</span>, <span class="op">{</span>
      <span class="va">y_pred</span> <span class="op">&lt;-</span> <span class="fu">self</span><span class="op">(</span><span class="va">x</span>, training <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>  <span class="co"># Forward pass</span>
      <span class="co"># Compute the loss value.</span>
      <span class="co"># The loss function is configured in `compile()`.</span>
      <span class="va">loss</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">compiled_loss</span><span class="op">(</span><span class="va">y</span>, <span class="va">y_pred</span>,
                                 sample_weight <span class="op">=</span> <span class="va">sample_weight</span>,
                                 regularization_losses <span class="op">=</span> <span class="va">self</span><span class="op">$</span><span class="va">losses</span><span class="op">)</span>
    <span class="op">}</span><span class="op">)</span>
    
    <span class="co"># Compute gradients</span>
    <span class="va">trainable_vars</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="va">trainable_variables</span>
    <span class="va">gradients</span> <span class="op">&lt;-</span> <span class="va">tape</span><span class="op">$</span><span class="fu">gradient</span><span class="op">(</span><span class="va">loss</span>, <span class="va">trainable_vars</span><span class="op">)</span>
    
    <span class="co"># Update weights</span>
    <span class="va">self</span><span class="op">$</span><span class="va">optimizer</span><span class="op">$</span><span class="fu">apply_gradients</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/zip.html">zip</a></span><span class="op">(</span><span class="va">gradients</span>, <span class="va">trainable_vars</span><span class="op">)</span><span class="op">)</span>
    
    <span class="co"># Update the metrics.</span>
    <span class="co"># Metrics are configured in `compile()`.</span>
    <span class="va">self</span><span class="op">$</span><span class="va">compiled_metrics</span><span class="op">$</span><span class="fu">update_state</span><span class="op">(</span><span class="va">y</span>, <span class="va">y_pred</span>, sample_weight <span class="op">=</span> <span class="va">sample_weight</span><span class="op">)</span>
    
    <span class="co"># Return a dict mapping metric names to current value.</span>
    <span class="co"># Note that it will include the loss (tracked in self$metrics).</span>
    <span class="fu">map_and_name</span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">metrics</span>, <span class="va">.x</span><span class="op">$</span><span class="va">name</span> <span class="op">~</span> <span class="va">.x</span><span class="op">$</span><span class="fu">result</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>
  <span class="op">}</span>
<span class="op">}</span>

<span class="co"># Construct and compile an instance of CustomModel</span>
<span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_input.html">layer_input</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html">shape</a></span><span class="op">(</span><span class="fl">32</span><span class="op">)</span><span class="op">)</span>
<span class="va">outputs</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span> <span class="fu"><a href="../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units<span class="op">=</span><span class="fl">1</span><span class="op">)</span>
<span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">CustomModel</span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span>
<span class="va">model</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span>optimizer<span class="op">=</span><span class="st">"adam"</span>, loss<span class="op">=</span><span class="st">"mse"</span>, metrics <span class="op">=</span> <span class="st">"mae"</span><span class="op">)</span>

<span class="co"># You can now use sample_weight argument</span>
<span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/k_random_uniform.html">k_random_uniform</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1000</span>, <span class="fl">32</span><span class="op">)</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/k_random_uniform.html">k_random_uniform</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1000</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="va">sw</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/k_random_uniform.html">k_random_uniform</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1000</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="va">model</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, sample_weight<span class="op">=</span><span class="va">sw</span>, epochs<span class="op">=</span><span class="fl">5</span><span class="op">)</span></code></pre></div>
</div>
<div id="providing-your-own-evaluation-step" class="section level2">
<h2 class="hasAnchor">
<a href="#providing-your-own-evaluation-step" class="anchor"></a>Providing your own evaluation step</h2>
<p>What if you want to do the same for calls to <code>model.evaluate()</code>? Then you would override <code>test_step</code> in exactly the same way. Here’s what it looks like:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">CustomModel</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">Model</span><span class="op">)</span> <span class="op"><a href="../../reference/%py_class%.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">test_step</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">data</span><span class="op">)</span> <span class="op">{</span>
    <span class="co"># Unpack the data</span>
    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span> <span class="op"><a href="../../reference/%&lt;-%.html">%&lt;-%</a></span> <span class="va">data</span>
    <span class="co"># Compute predictions</span>
    <span class="va">y_pred</span> <span class="op">&lt;-</span> <span class="fu">self</span><span class="op">(</span><span class="va">x</span>, training <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
    <span class="co"># Updates the metrics tracking the loss</span>
    <span class="va">self</span><span class="op">$</span><span class="fu">compiled_loss</span><span class="op">(</span><span class="va">y</span>, <span class="va">y_pred</span>, regularization_losses <span class="op">=</span> <span class="va">self</span><span class="op">$</span><span class="va">losses</span><span class="op">)</span>
    <span class="co"># Update the metrics.</span>
    <span class="va">self</span><span class="op">$</span><span class="va">compiled_metrics</span><span class="op">$</span><span class="fu">update_state</span><span class="op">(</span><span class="va">y</span>, <span class="va">y_pred</span><span class="op">)</span>
    <span class="co"># Return a dict mapping metric names to current value.</span>
    <span class="co"># Note that it will include the loss (tracked in self.metrics).</span>
    <span class="fu">map_and_name</span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">metrics</span>, <span class="va">.x</span><span class="op">$</span><span class="va">name</span> <span class="op">~</span> <span class="va">.x</span><span class="op">$</span><span class="fu">result</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>
  <span class="op">}</span>
<span class="op">}</span>


<span class="co"># Construct an instance of CustomModel</span>
<span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_input.html">layer_input</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html">shape</a></span><span class="op">(</span><span class="fl">32</span><span class="op">)</span><span class="op">)</span>
<span class="va">outputs</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span> <span class="fu"><a href="../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units<span class="op">=</span><span class="fl">1</span><span class="op">)</span>
<span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">CustomModel</span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span>
<span class="va">model</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span>loss<span class="op">=</span><span class="st">"mse"</span>, metrics <span class="op">=</span> <span class="st">"mae"</span><span class="op">)</span>

<span class="co"># Evaluate with our custom test_step</span>
<span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="../../reference/k_random_uniform.html">k_random_uniform</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1000</span>, <span class="fl">32</span><span class="op">)</span><span class="op">)</span>
<span class="va">y</span> <span class="op">=</span> <span class="fu"><a href="../../reference/k_random_uniform.html">k_random_uniform</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1000</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="va">model</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/evaluate.html">evaluate</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span></code></pre></div>
<pre><code>##     loss      mae 
## 2.375309 1.457297</code></pre>
</div>
<div id="wrapping-up-an-end-to-end-gan-example" class="section level2">
<h2 class="hasAnchor">
<a href="#wrapping-up-an-end-to-end-gan-example" class="anchor"></a>Wrapping up: an end-to-end GAN example</h2>
<p>Let’s walk through an end-to-end example that leverages everything you just learned.</p>
<p>Let’s consider:</p>
<ul>
<li>A generator network meant to generate 28x28x1 images.</li>
<li>A discriminator network meant to classify 28x28x1 images into two classes (“fake” and “real”).</li>
<li>One optimizer for each.</li>
<li>A loss function to train the discriminator.</li>
</ul>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Create the discriminator</span>
<span class="va">discriminator</span> <span class="op">&lt;-</span>
  <span class="fu"><a href="../../reference/keras_model_sequential.html">keras_model_sequential</a></span><span class="op">(</span>name <span class="op">=</span> <span class="st">"discriminator"</span><span class="op">)</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span>
  <span class="fu"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span><span class="op">(</span><span class="fl">64</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">3</span><span class="op">)</span>, strides <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span>, padding <span class="op">=</span> <span class="st">"same"</span>, 
                input_shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">28</span>, <span class="fl">28</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span>
  <span class="fu"><a href="../../reference/layer_activation_leaky_relu.html">layer_activation_leaky_relu</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span>
  <span class="fu"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span><span class="op">(</span><span class="fl">128</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">3</span><span class="op">)</span>, strides <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span>, padding <span class="op">=</span> <span class="st">"same"</span><span class="op">)</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span>
  <span class="fu"><a href="../../reference/layer_activation_leaky_relu.html">layer_activation_leaky_relu</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span>
  <span class="fu"><a href="../../reference/layer_global_max_pooling_2d.html">layer_global_max_pooling_2d</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span>
  <span class="fu"><a href="../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>


<span class="co"># Create the generator</span>
<span class="va">latent_dim</span> <span class="op">&lt;-</span> <span class="fl">128L</span>
<span class="va">generator</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/keras_model_sequential.html">keras_model_sequential</a></span><span class="op">(</span>name <span class="op">=</span> <span class="st">"generator"</span><span class="op">)</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span>
  <span class="co"># We want to generate 128 coefficients to reshape into a 7x7x128 map</span>
  <span class="fu"><a href="../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="fl">7</span> <span class="op">*</span> <span class="fl">7</span> <span class="op">*</span> <span class="fl">128</span>, input_shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">latent_dim</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span>
  <span class="fu"><a href="../../reference/layer_activation_leaky_relu.html">layer_activation_leaky_relu</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span>
  <span class="fu"><a href="../../reference/layer_reshape.html">layer_reshape</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">7</span>, <span class="fl">7</span>, <span class="fl">128</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span>
  <span class="fu"><a href="../../reference/layer_conv_2d_transpose.html">layer_conv_2d_transpose</a></span><span class="op">(</span><span class="fl">128</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">4</span><span class="op">)</span>, strides <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span>, padding <span class="op">=</span> <span class="st">"same"</span><span class="op">)</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span>
  <span class="fu"><a href="../../reference/layer_activation_leaky_relu.html">layer_activation_leaky_relu</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span>
  <span class="fu"><a href="../../reference/layer_conv_2d_transpose.html">layer_conv_2d_transpose</a></span><span class="op">(</span><span class="fl">128</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">4</span><span class="op">)</span>, strides <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span>, padding <span class="op">=</span> <span class="st">"same"</span><span class="op">)</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span>
  <span class="fu"><a href="../../reference/layer_activation_leaky_relu.html">layer_activation_leaky_relu</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span>
  <span class="fu"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">7</span>, <span class="fl">7</span><span class="op">)</span>, padding <span class="op">=</span> <span class="st">"same"</span>, activation <span class="op">=</span> <span class="st">"sigmoid"</span><span class="op">)</span></code></pre></div>
<p>Here’s a feature-complete GAN class, overriding <code><a href="https://generics.r-lib.org/reference/compile.html">compile()</a></code> to use its own signature, and implementing the entire GAN algorithm in 17 lines in <code>train_step</code>:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">GAN</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">Model</span><span class="op">)</span> <span class="op"><a href="../../reference/%py_class%.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">`__init__`</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">discriminator</span>, <span class="va">generator</span>, <span class="va">latent_dim</span><span class="op">)</span> <span class="op">{</span>
        <span class="fu">super</span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="fu">`__init__`</span><span class="op">(</span><span class="op">)</span>
        <span class="va">self</span><span class="op">$</span><span class="va">discriminator</span> <span class="op">&lt;-</span> <span class="va">discriminator</span>
        <span class="va">self</span><span class="op">$</span><span class="va">generator</span> <span class="op">&lt;-</span> <span class="va">generator</span>
        <span class="va">self</span><span class="op">$</span><span class="va">latent_dim</span> <span class="op">&lt;-</span> <span class="va">latent_dim</span>
  <span class="op">}</span>

  <span class="va">compile</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">d_optimizer</span>, <span class="va">g_optimizer</span>, <span class="va">loss_fn</span><span class="op">)</span> <span class="op">{</span>
    <span class="fu">super</span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="fu">compile</span><span class="op">(</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">d_optimizer</span> <span class="op">&lt;-</span> <span class="va">d_optimizer</span>
    <span class="va">self</span><span class="op">$</span><span class="va">g_optimizer</span> <span class="op">&lt;-</span> <span class="va">g_optimizer</span>
    <span class="va">self</span><span class="op">$</span><span class="va">loss_fn</span> <span class="op">=</span> <span class="va">loss_fn</span>
  <span class="op">}</span>

  <span class="va">train_step</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">real_images</span><span class="op">)</span> <span class="op">{</span>

    <span class="co"># Sample random points in the latent space</span>
    <span class="va">batch_size</span> <span class="op">=</span> <span class="va">tf</span><span class="op">$</span><span class="fu">shape</span><span class="op">(</span><span class="va">real_images</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>

    <span class="co"># TODO: shape() should be able to handle a scalar tensor as input</span>
    <span class="co"># also, backend functions like k_random_normal</span>
    <span class="va">random_latent_vectors</span> <span class="op">=</span> <span class="va">tf</span><span class="op">$</span><span class="va">random</span><span class="op">$</span><span class="fu">normal</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">batch_size</span>, <span class="va">self</span><span class="op">$</span><span class="va">latent_dim</span><span class="op">)</span><span class="op">)</span>

    <span class="co"># Decode them to fake images</span>
    <span class="va">generated_images</span> <span class="op">=</span> <span class="va">self</span><span class="op">$</span><span class="fu">generator</span><span class="op">(</span><span class="va">random_latent_vectors</span><span class="op">)</span>

    <span class="co"># Combine them with real images</span>
    <span class="va">combined_images</span> <span class="op">=</span> <span class="va">tf</span><span class="op">$</span><span class="fu">concat</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">generated_images</span>, <span class="va">real_images</span><span class="op">)</span>,
                                axis <span class="op">=</span> <span class="fl">0L</span><span class="op">)</span>

    <span class="co"># Assemble labels discriminating real from fake images</span>
    <span class="va">labels</span> <span class="op">=</span> <span class="va">tf</span><span class="op">$</span><span class="fu">concat</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">ones</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">batch_size</span>, <span class="fl">1L</span><span class="op">)</span><span class="op">)</span>,
                            <span class="va">tf</span><span class="op">$</span><span class="fu">zeros</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">batch_size</span>, <span class="fl">1L</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, axis <span class="op">=</span> <span class="fl">0L</span><span class="op">)</span>
    
    <span class="co"># Add random noise to the labels - important trick!</span>
    <span class="va">labels</span> <span class="op">%&lt;&gt;%</span> <span class="fu">`+`</span><span class="op">(</span><span class="fl">0.05</span> <span class="op">*</span> <span class="va">tf</span><span class="op">$</span><span class="va">random</span><span class="op">$</span><span class="fu">uniform</span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">shape</span><span class="op">(</span><span class="va">labels</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>

    <span class="co"># Train the discriminator</span>
    <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">GradientTape</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/reticulate/man/with-as-operator.html">%as%</a></span> <span class="va">tape</span>, <span class="op">{</span>
      <span class="va">predictions</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">discriminator</span><span class="op">(</span><span class="va">combined_images</span><span class="op">)</span>
      <span class="va">d_loss</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">loss_fn</span><span class="op">(</span><span class="va">labels</span>, <span class="va">predictions</span><span class="op">)</span>
    <span class="op">}</span><span class="op">)</span>
    <span class="va">grads</span> <span class="op">&lt;-</span> <span class="va">tape</span><span class="op">$</span><span class="fu">gradient</span><span class="op">(</span><span class="va">d_loss</span>, <span class="va">self</span><span class="op">$</span><span class="va">discriminator</span><span class="op">$</span><span class="va">trainable_weights</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">d_optimizer</span><span class="op">$</span><span class="fu">apply_gradients</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/zip.html">zip</a></span><span class="op">(</span><span class="va">grads</span>, <span class="va">self</span><span class="op">$</span><span class="va">discriminator</span><span class="op">$</span><span class="va">trainable_weights</span><span class="op">)</span><span class="op">)</span>

    <span class="co"># Sample random points in the latent space</span>
    <span class="va">random_latent_vectors</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="va">random</span><span class="op">$</span><span class="fu">normal</span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">batch_size</span>, <span class="va">self</span><span class="op">$</span><span class="va">latent_dim</span><span class="op">)</span><span class="op">)</span>

    <span class="co"># Assemble labels that say "all real images"</span>
    <span class="va">misleading_labels</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">zeros</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">batch_size</span>, <span class="fl">1L</span><span class="op">)</span><span class="op">)</span>

    <span class="co"># Train the generator (note that we should *not* update the weights</span>
    <span class="co"># of the discriminator)!</span>
    <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">GradientTape</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/reticulate/man/with-as-operator.html">%as%</a></span> <span class="va">tape</span>, <span class="op">{</span>
      <span class="va">predictions</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">discriminator</span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="fu">generator</span><span class="op">(</span><span class="va">random_latent_vectors</span><span class="op">)</span><span class="op">)</span>
      <span class="va">g_loss</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">loss_fn</span><span class="op">(</span><span class="va">misleading_labels</span>, <span class="va">predictions</span><span class="op">)</span>
    <span class="op">}</span><span class="op">)</span>
    <span class="va">grads</span> <span class="op">&lt;-</span> <span class="va">tape</span><span class="op">$</span><span class="fu">gradient</span><span class="op">(</span><span class="va">g_loss</span>, <span class="va">self</span><span class="op">$</span><span class="va">generator</span><span class="op">$</span><span class="va">trainable_weights</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">g_optimizer</span><span class="op">$</span><span class="fu">apply_gradients</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/zip.html">zip</a></span><span class="op">(</span><span class="va">grads</span>, <span class="va">self</span><span class="op">$</span><span class="va">generator</span><span class="op">$</span><span class="va">trainable_weights</span><span class="op">)</span><span class="op">)</span>
    <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>d_loss <span class="op">=</span> <span class="va">d_loss</span>, g_loss <span class="op">=</span> <span class="va">g_loss</span><span class="op">)</span>
  <span class="op">}</span>

<span class="op">}</span></code></pre></div>
<p>Let’s test-drive it:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Prepare the dataset. We use both the training &amp; test MNIST digits.</span>

<span class="va">batch_size</span> <span class="op">&lt;-</span> <span class="fl">64</span>

<span class="va">ds</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/dataset_mnist.html">dataset_mnist</a></span><span class="op">(</span><span class="op">)</span>
<span class="va">all_digits</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/k_concatenate.html">k_concatenate</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">ds</span><span class="op">$</span><span class="va">train</span><span class="op">$</span><span class="va">x</span>, <span class="va">ds</span><span class="op">$</span><span class="va">test</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>, axis<span class="op">=</span><span class="fl">1</span><span class="op">)</span>
<span class="va">all_digits</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/k_cast.html">k_cast</a></span><span class="op">(</span><span class="va">all_digits</span>, <span class="st">"float32"</span><span class="op">)</span> <span class="op">/</span> <span class="fl">255.0</span>
<span class="va">all_digits</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/k_reshape.html">k_reshape</a></span><span class="op">(</span><span class="va">all_digits</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">28</span>, <span class="fl">28</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span>

<span class="va">dataset</span> <span class="op">&lt;-</span> <span class="va">all_digits</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span>
  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/tensor_slices_dataset.html">tensor_slices_dataset</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span>
  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_shuffle.html">dataset_shuffle</a></span><span class="op">(</span>buffer_size <span class="op">=</span> <span class="fl">1024</span><span class="op">)</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span>
  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_batch.html">dataset_batch</a></span><span class="op">(</span><span class="va">batch_size</span><span class="op">)</span>


<span class="va">gan</span> <span class="op">&lt;-</span> <span class="fu">GAN</span><span class="op">(</span>discriminator <span class="op">=</span> <span class="va">discriminator</span>,
           generator <span class="op">=</span> <span class="va">generator</span>,
           latent_dim <span class="op">=</span> <span class="va">latent_dim</span><span class="op">)</span>

<span class="va">gan</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span>
  d_optimizer <span class="op">=</span> <span class="va">keras</span><span class="op">$</span><span class="va">optimizers</span><span class="op">$</span><span class="fu">Adam</span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="fl">0.0003</span><span class="op">)</span>,
  g_optimizer <span class="op">=</span> <span class="va">keras</span><span class="op">$</span><span class="va">optimizers</span><span class="op">$</span><span class="fu">Adam</span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="fl">0.0003</span><span class="op">)</span>,
  loss_fn <span class="op">=</span> <span class="va">keras</span><span class="op">$</span><span class="va">losses</span><span class="op">$</span><span class="fu">BinaryCrossentropy</span><span class="op">(</span>from_logits <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="op">)</span>

<span class="co"># To limit the execution time, we only train on 100 batches. You can train on</span>
<span class="co"># the entire dataset. You will need about 20 epochs to get nice results.</span>
<span class="va">dataset</span> <span class="op">%&lt;&gt;%</span> <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_take.html">dataset_take</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span>

<span class="va">gan</span> <span class="op"><a href="../../reference/%&gt;%.html">%&gt;%</a></span>
  <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span><span class="va">dataset</span>, epochs<span class="op">=</span><span class="fl">1</span><span class="op">)</span></code></pre></div>
<p>The ideas behind deep learning are simple, so why should their implementation be painful?</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet,  RStudio,  Google.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
